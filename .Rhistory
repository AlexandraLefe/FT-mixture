# if initial eta is provided, retrieve K
K = ncol(eta) - 1
}
# theta.tol introduced to check algorithm convergence
theta.tol = rep(0, 3*(K+1))
for (iter in 1:niter) {
# M step
pi = apply(eta,2,sum) / n
df = data.frame(x = rep(c(t(x)), K+1), d = rep(c(t(d)), K+1), time = rep(time, n*(K+1)), z = as.factor(rep(0:K, each = n*nT)))
weights = NULL
for (k in 0:K) weights = c(weights, rep(eta[,k+1], each = nT))
if (K > 0) {
fit = glm(cbind(x, d - x) ~ 0 + z + time:z, "binomial", df, weights)
} else {
fit = glm(cbind(x, d - x) ~ 1 + time, "binomial", df, weights)
}
tmp = coefficients(fit)
mu = tmp[1:(K+1)];
s = tmp[(K+1)+(1:(K+1))]
# E step
eta = matrix(0, nrow = n, ncol = K+1)
for (i in 1:n) for (k in 0:K) {
prob = exp(mu[k+1] + time * s[k+1])
prob = prob / (1 + prob)
prob[prob==1.0] = 1-1e-10; prob[prob==0.0] = 1e-10
eta[i,k+1] = sum(dbinom(x[i,], d[i,], prob, log = TRUE)) + log(pi[k+1])
}
aux = apply(eta, 1, logsumexp)
loglik = sum(aux)
eta = exp(eta - aux)
if(verbose) {
cat("loglik=",loglik, "theta.tol=", theta.tol,"\n")
}
# check convergence
if(max(abs(theta.tol - c(pi,mu, s)) / abs(c(pi,mu, s))) < tol) break;
theta.tol = c(pi, mu, s)
}
return(list(loglik = loglik, pi = pi, mu = mu, s = s, eta = eta))
}
# first step : perform n.pre.it iteration over em.initialization and keep eta associated to the best log-likelihood
pre.loglik = -Inf # initial log-likelihood of em.initialization
j=1
while (j <= n.pre.init[k]) {
tmp = try(em.initialization(data, K + k, eta = NULL, niter = n.pre.it[k], verbose = FALSE))
if (class(tmp)!= "try-error") {
if(verbose) {cat("rep.pre.init =",j, "loglik =", tmp$loglik,"\n")}
if(tmp$loglik > pre.loglik) {pre.loglik = tmp$loglik; pre.init = tmp}
j = j+1
}
}
run_algorithm <- function(data, K,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE) {
check.init = NULL
loglik = -Inf # initial log-likelihood
# propose initial values computed with em.initialization over a model composed of a total of K+2 and K+3 groups
for (k in which(n.init!=0)) {
if(verbose) cat("k =",k,"\n")
i = 1
while (i <= n.init[k]) {
# first step : compute initial eta for em.ft.clust
# perform n.pre.init times n.pre.it iterations over em.initialization and keep eta associated to the best log-likelihood
pre.loglik = -Inf
j=1
while (j <= n.pre.init[k]) {
tmp = try(em.initialization(data, K + k, eta = NULL, niter = n.pre.it[k], verbose = FALSE))
if (class(tmp)!= "try-error") {
if(verbose) {cat("rep.pre.init =",j, "loglik =", tmp$loglik,"\n")}
if(tmp$loglik > pre.loglik) {pre.loglik = tmp$loglik; pre.init = tmp}
j = j+1
}
}
# 2nd step : Perform n.it iterations of em.ft.clust over the initial eta selected
# extract initial neutral group by fusing the k+1 groups of lowest absolute value for s
idx = sort.int(abs(pre.init$s), index.return = TRUE)$ix
tmp = try(em(data, K, eta = cbind(apply(pre.init$eta[,-tail(idx,K)], 1, sum), pre.init$eta[,tail(idx,K)]),
verbose = verbose, niter = n.it[k]))
# store associated loglikelihood of check.initialization is TRUE
if (check.initialization) {
check.init = c(check.init, ifelse(class(tmp)!="try-error", tmp$loglik, "error"))
}
# keep 'init' as eta if it is  associated to the best loglik
if(class(tmp)!="try-error") {
if(tmp$loglik > loglik) {
loglik = tmp$loglik; init = tmp
}
}
# test subsequent value of initial eta
i = i + 1
}
# test next model (composed of increasing total number of groups)
k = k + 1
}
# run algorithm until convergence with init associated to best log-likelihood
res = try(em.ft.clust(data, K, eta = init$eta, tol = 1e-5, verbose = verbose))
if(check.initialization) {
names(check.init) = c(rep("K+2", n.init[1]), rep("K+3", n.init[2]))
res$check.initialization = check.init
}
return(res = res)
}
data
K
K=2
ft.clust(data,K)
ft.clust <- function(data, K,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE) {
check.init = NULL
loglik = -Inf # initial log-likelihood
# propose initial values computed with em.initialization over a model composed of a total of K+2 and K+3 groups
for (k in which(n.init!=0)) {
if(verbose) cat("k =",k,"\n")
i = 1
while (i <= n.init[k]) {
# first step : compute initial eta for em.ft.clust
# perform n.pre.init times n.pre.it iterations over em.initialization and keep eta associated to the best log-likelihood
pre.loglik = -Inf
j=1
while (j <= n.pre.init[k]) {
tmp = try(em.initialization(data, K + k, eta = NULL, niter = n.pre.it[k], verbose = FALSE))
if (class(tmp)!= "try-error") {
if(verbose) {cat("rep.pre.init =",j, "loglik =", tmp$loglik,"\n")}
if(tmp$loglik > pre.loglik) {pre.loglik = tmp$loglik; pre.init = tmp}
j = j+1
}
}
# 2nd step : Perform n.it iterations of em.ft.clust over the initial eta selected
# extract initial neutral group by fusing the k+1 groups of lowest absolute value for s
idx = sort.int(abs(pre.init$s), index.return = TRUE)$ix
tmp = try(em(data, K, eta = cbind(apply(pre.init$eta[,-tail(idx,K)], 1, sum), pre.init$eta[,tail(idx,K)]),
verbose = verbose, niter = n.it[k]))
# store associated loglikelihood of check.initialization is TRUE
if (check.initialization) {
check.init = c(check.init, ifelse(class(tmp)!="try-error", tmp$loglik, "error"))
}
# keep 'init' as eta if it is  associated to the best loglik
if(class(tmp)!="try-error") {
if(tmp$loglik > loglik) {
loglik = tmp$loglik; init = tmp
}
}
# test subsequent value of initial eta
i = i + 1
}
# test next model (composed of increasing total number of groups)
k = k + 1
}
# run algorithm until convergence with init associated to best log-likelihood
res = try(em.ft.clust(data, K, eta = init$eta, tol = 1e-5, verbose = verbose))
if(check.initialization) {
names(check.init) = c(rep("K+2", n.init[1]), rep("K+3", n.init[2]))
res$check.initialization = check.init
}
return(res = res)
}
ft.clust(data,K)
res = ft.clust(data,K)
ft.clust(data,K)
res$
pi
pi
# simulation scheme (example)
n = 200
time = c(0, 5, 12, 20)
pi = c(0.6, 0.3, 0.1)
s = c(-1,2) / max(time) # divide by max time in order to have reasonable frequency trajectory
mu = c(0.5,-3)
alpha = 10
beta = 50
lambda = 40
simu = generate_simu(n=n, time=time, pi=pi, s=s, mu=mu, alpha=alpha, beta=beta, lambda=lambda)
data=simu$data
n
# plot raw trajectories (verification)
plot(0, type = "n", xlim = range(time), ylim = c(0,1))
for (i in 1:n) {
lines(time, (simu$data$x/simu$data$d)[i,], col = simu$z[i]+1)
}
# source R code
source("R_code/EM_algorithm.R")
# run algorithm for a chosen K
ft.clust (data = simu$data, K,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE)
# run algorithm for a chosen K
res = ft.clust (data = simu$data, K,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE)
res$pi
res$s
s
res$mu
mu
res$eta
source("/R_code/generate_simu")
source("/R_code/generate_simulated_data")
source("R_code/generate_simulated_data")
source("R_code/EM_algorithm.R")
source("R_code/generate_simulated_data.R")
require(VGAM)
source("R_code/generate_simulated_data.R")
source("R_code/EM_algorithm.R")
# generated simulated dataset
simu = generate_simu(n = 200,
time = c(0, 5, 12, 20),
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / 20, #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40)
source("R_code/generate_simulated_data.R")
source("R_code/EM_algorithm.R")
# generated simulated dataset
simu = generate_simu(n = 200,
time = c(0, 5, 12, 20),
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / 20, #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40)
# generated simulated dataset
simu = generate_simu(n = 200,
time = c(0, 5, 12, 20),
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / 20, #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40)
#' @param n single value for the number of mutations
#' @param time vector of size nT (number of time points) for the time differences (usually in days) between sampling date and time origin. First slot is zero
#' @param K single value for the number of non-neutral groups
#' @param pi vector of size K+1 for group proportions
#' @param mu vector of size K for the logit of the frequency trajectory of non-neutral groups
#' @param s vector of size K for selection coefficients of non-neutral groups
#' @param alpha and beta : single values for the parameters of the betabinomial distribution of the intercept of the neutral group.
#' @param lambda single value for the mean of the poisson distribution for read depths
#'
#' @return a list of a dataset (list of a matrix mutation count and a matrix of read depth), a vector z of group assignment and a list of parameters
generate_simu <- function(n, time, pi, s, mu, alpha, beta, lambda) {
# number of time points
nT = length(time)
# number of non-neutral groups
K = length(pi) - 1
# group assignment
z = NULL; while(length(unique(z)) != K+1) {z = sample(0:K, n, replace = TRUE, prob = pi)}
# matrix of read depth
d = matrix(rpois(n * nT, lambda = lambda), n, nT)
# matrix of mutation counts
x = matrix(NA,n,nT)
for (i in 1:n) {
k = z[i]
if (k==0) {
x[i,] = rbinom(nT,d[i,],rbeta(1,alpha,beta)) # n=1 in rbeta because u is not indep of t (same u for one mutation)
} else {
x[i,] = rbinom(nT,d[i,],exp(mu[k] + s[k]*time) / (1+exp(mu[k] + s[k]*time)))
}
}
# add column names
colnames(x) = colnames(d) = as.character(as.Date ("2020-01-01") + time)
data = list(x = x, d = d)
# # verify raw trajecteories
# plot(1, type = "n", xlab = "time", ylab = "frequency", xlim = range(time), ylim = c(0,1))
# for (i in 1:n) {
#   lines(time, (x/d)[i,], col=z[i]+1)
# }
return(list(data = list(x=x, d=d), z = z, param = list(pi=pi, s=s, mu=mu, alpha=alpha, beta=beta, lambda=lambda)))
}
source("R_code/generate_simulated_data.R")
# generated simulated dataset
simu = generate_simu(n = 200,
time = c(0, 5, 12, 20),
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / 20, #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40)
require(VGAM)
source("R_code/generate_simulated_data.R")
source("R_code/EM_algorithm.R")
# generated simulated dataset
simu = generate_simu(n = 200,
time = c(0, 5, 12, 20),
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / 20, #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40)
# run algorithm for a chosen K
res = ft.clust (data = simu$data,
K = 2,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE)
# run algorithm for a chosen K
res = ft.clust (data = simu$data,
K = 2,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE)
require(VGAM)
source("R_code/generate_simulated_data.R")
source("R_code/EM_algorithm.R")
# generated simulated dataset
simu = generate_simu(n = 200,
time = c(0, 5, 12, 20),
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / 20, #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40)
# run algorithm for a chosen K
res = ft.clust (data = simu$data,
K = 2,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE)
?sort.int
require(VGAM)
source("R_code/generate_simulated_data.R")
source("R_code/EM_algorithm.R")
# generated simulated dataset
n = 200
time = c(0, 5, 12, 20)
pi.star = c(0.6, 0.3, 0.1)
s.star = c(-1,2) / max(time) #divided by the max(time) for reasonable frequency trajectory
mu.star = c(0.5,-3)
alpha.star = 10
beta.star = 50
lambda.star = 40
simu = generate_simu(n = n,
time = time,
pi = pi.star,
s = s.star, #divided by the max(time) for reasonable frequency trajectory
mu = mu.star,
alpha = alpha.star,
beta = beta.star,
lambda = lambda.star)
# run algorithm for a chosen K
res = ft.clust (data = simu$data,
K = 2,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE)
K.star = length(pi)-1
K.star
K.star = length(pi.star)-1
# run algorithm for a chosen K
res = ft.clust (data = simu$data,
K = K.star,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE)
res
K.star
# generated simulated dataset
n = 200
time = c(0, 5, 12, 20)
param.star = list(
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / max(time), #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40,
)
param.star = list(
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / max(time), #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40,
)
param.star
list(
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / max(time), #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40,
)
list(pi=1:2, fg='re')
c(-1,2) / max(time)
param.star = list(
pi = c(0.6, 0.3, 0.1),
#s = c(-1,2) / max(time), #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40,
)
param.star = list(
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / max(time), #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40
)
K.star = length(param.star$pi)-1
simu = generate_simu(n = n,
time = time,
pi = param.star$pi,
s = param.star$s, #divided by the max(time) for reasonable frequency trajectory
mu = param.star$mu,
alpha = param.star$alpha,
beta = param.star$beta,
lambda = param.star$lambda)
require(VGAM)
source("R_code/generate_simulated_data.R")
source("R_code/EM_algorithm.R")
# generated simulated dataset
n = 200
time = c(0, 5, 12, 20)
param.star = list(
pi = c(0.6, 0.3, 0.1),
s = c(-1,2) / max(time), #divided by the max(time) for reasonable frequency trajectory
mu = c(0.5,-3),
alpha = 10,
beta = 50,
lambda = 40
)
K.star = length(param.star$pi)-1
simu = generate_simu(n = n,
time = time,
pi = param.star$pi,
s = param.star$s, #divided by the max(time) for reasonable frequency trajectory
mu = param.star$mu,
alpha = param.star$alpha,
beta = param.star$beta,
lambda = param.star$lambda)
# run algorithm for a chosen K
res = ft.clust (data = simu$data,
K = K.star,
n.pre.init = c(5,5), n.pre.it = c(5,5),
n.init = c(10,10), n.it = c(5,5),
check.initialization = TRUE,
verbose = TRUE)
# handle label switching
perm = permutations(K, K, repeats.allowed = FALSE)
require(readr)
# handle label switching
perm = permutations(K, K, repeats.allowed = FALSE)
?permutations
require(gtools)
# handle label switching
perm = permutations(K, K, repeats.allowed = FALSE)
# handle label switching
perm = permutations(K.star, K.star, repeats.allowed = FALSE)
idx = perm[which.min(apply((matrix(res$mu[perm], K.star, K.star,byrow = TRUE) - matrix(mu.star, K.star, K.star, byrow = TRUE))^2, 1, sum) + apply((matrix(res$s[perm]*norm.time, K.star, K.star,byrow = TRUE) - matrix(s.star*norm.time, K.star, K.star,byrow = TRUE))^2, 1, sum)),]
norm.time
param.star$s
# handle label switching
perm = permutations(K.star, K.star, repeats.allowed = FALSE)
idx = perm[which.min(apply((matrix(res$mu[perm], K.star, K.star, byrow = TRUE) -
matrix(param.star$mu, K.star, K.star, byrow = TRUE))^2, 1, sum) +
apply((matrix(res$s[perm]*max(time), K.star, K.star, byrow = TRUE) -
matrix(param.star$s*max(time), K.star, K.star, byrow = TRUE))^2, 1, sum)),]
idx
res$pi = res$pi[c(1,idx+1)]
res$s = res$s[idx]
res$mu = res$mu[idx]
res
res$pi
param.star$pi
paste0("mut.",1:n)
generate_simu <- function(n, time.diff, time.origin = NULL, pi, s, mu, alpha, beta, lambda) {
# number of time points
nT = length(time)
# number of non-neutral groups
K = length(pi) - 1
# group assignment
z = NULL; while(length(unique(z)) != K+1) {z = sample(0:K, n, replace = TRUE, prob = pi)}
# matrix of read depth
d = matrix(rpois(n * nT, lambda = lambda), n, nT)
# matrix of mutation counts
x = matrix(NA,n,nT)
for (i in 1:n) {
k = z[i]
if (k==0) {
x[i,] = rbinom(nT,d[i,],rbeta(1,alpha,beta))
} else {
x[i,] = rbinom(nT,d[i,],exp(mu[k] + s[k]*time) / (1+exp(mu[k] + s[k]*time)))
}
}
# add names
colnames(x) = colnames(d) = as.character(as.Date (ifelse(is.null(date.origin), "2020-01-01", date.origin)) + time)
rownames(x) = rownames(d) = paste0("mut.",1:n)
data = list(x = x, d = d)
return(list(data = list(x=x, d=d), z = z, param = list(pi=pi, s=s, mu=mu, alpha=alpha, beta=beta, lambda=lambda)))
}
